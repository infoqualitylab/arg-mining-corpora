{
  "papers": [
    {
      "paper_id": "an_annotated_corpus_of_argumentative_microtexts",
      "paper_title": "An annotated corpus of argumentative microtexts",
      "authors": [
        "Andreas Peldzus",
        "Manfred Stede"
      ],
      "description": "Introduce a corpus for exploring text-level argumentation structure in German and professionally translated English.",
      "year": 2016,
      "paper_link": "https://www.ling.uni-potsdam.de/~peldszus/eca2015-preprint.pdf",
      "annotations": [
        {
          "corpus_id": "microtexts_v1",
          "annotation_task": [
            "Argument Component Segmentation",
            "Argument Component Type Classification",
            "Argumentative Relation Identification",
            "Argumentative Relation Type Classification"
          ],
          "description": "Texts are segmented into Argumentative Discourse Units (ADUs) with support and attack links.",
          "annotator_count": 3,
          "annotator_type": [
            "Expert",
            "Other"
          ],
          "agreement_type": "Fleiss' Kappa",
          "agreement_score": 0.83,
          "accessibility": "Free",
          "corpus_link": "https://github.com/peldszus/arg-microtexts"
        }
      ]
    },
    {
      "paper_id": "a_news_editorial_corpus_for_argumentation_mining_strategies",
      "paper_title": "A news editorial corpus for argumentation mining strategies",
      "authors": [
        "Khalid Al-Khatib",
        "Henning Wachsmuth",
        "Johannes Kiesel",
        "Matthias Hagen",
        "Benno Stein"
      ],
      "description": "Exploring how argument is structured in a number of news editorials.",
      "year": 2016,
      "paper_link": "https://aclanthology.org/C16-1324/",
      "open_alex_id": "https://openalex.org/W2579772177",
      "annotations": [
        {
          "corpus_id": "webis_editorials_16",
          "annotation_task" : [
            "Argument Component Segmentation",
            "Argument Component Type Classification"
          ],
          "description": "Each ADU is labeled as one of six types: Assumption (general opinions), Anecdote (stories or examples), Testimony (expert or personal statements), Statistics (numerical data), Common Ground (shared beliefs), or Other (miscellaneous).",
          "annotator_count": 4,
          "annotator_type": [
            "Expert"
          ],
          "agreement_type": "Fleiss' Kappa",
          "agreement_score": 0.56,
          "accessibility": "Free",
          "corpus_link": "https://webis.de/data/webis-editorials-16.html"
        }
      ]
    },
    {
      "paper_id": "annotating_agreement_and_disagreement_in_threaded_discussion",
      "paper_title": "Annotating agreement and disagreement in threaded discussion",
      "authors": [
        "Jacob Andreas",
        "Sara Rosenthal",
        "Kathy McKeown"
      ],
      "description": "Identifying agreement and disagreement in Wikipedia Talk pages discussing content edits where editors discuss article revisions, propose changes, and resolve disputes. These discussions are typically formal yet conversational.",
      "year": 2012,
      "paper_link": "https://aclanthology.org/L12-1650/",
      "open_alex_id": "https://openalex.org/W2251588411",
      "annotations": [
        {
          "corpus_id": "agreement_in_wikipedia_talk_pages",
          "annotation_task": [
            "Argumentative Relation Type Classification",
            "Other"
          ],
          "description": "Annotating question-response pairs in threads with one of 5 modes: agreement-response, agreement-paraphrase, disagreement-response and disagreement-paraphrase.",
          "annotator_count": 2,
          "annotator_type": [
            "Student"
          ],
          "agreement_type": "Cohen's Kappa",
          "agreement_score": 0.66,
          "accessibility": "Free",
          "corpus_link": "https://www.cs.columbia.edu/~sara/data.php"
        },
        {
          "corpus_id": "agreement_in_wikipedia_talk_pages",
          "annotation_task": [
            "Argumentative Relation Type Classification"
          ],
          "description": "Annotating question-response pairs in threads with one of three relation types: agreement, disagreement, or none.",
          "annotator_count": 2,
          "annotator_type": [
            "Student"
          ],
          "agreement_type": "Cohen's Kappa",
          "agreement_score": 0.73,
          "accessibility": "Free",
          "corpus_link": "https://www.cs.columbia.edu/~sara/data.php"
        }
      ]
    },
    {
      "paper_id": "backup_your_stance",
      "paper_title": "Back up your stance: Recognizing arguments in online discussions",
      "authors": [
        "Filip Boltužić",
        "Jan Šnajder"
      ],
      "description": "Exploring the task of argument recognition in online discussions, trying to identify what arguments from a predefined set have been used in a user's comments and how.",
      "year": 2014,
      "paper_link": "https://aclanthology.org/W14-2107/",
      "open_alex_id": "https://openalex.org/W2250397934",
      "doi": "https://doi.org/10.3115/v1/w14-2107",
      "annotations": [
        {
          "corpus_id": "comarg",
          "annotation_task": [
            "Argumentative Relation Type Classification"
          ],
          "description": "Annotating the support or attack relationships between user comments and arguments given for a topic. NOTE: paper reports multiple types of agreement, we only note Fleiss' Kappa here.",
          "annotator_count": 3,
          "annotator_type": [
            "Expert"
          ],
          "agreement_type": "Fleiss' Kappa",
          "agreement_score": 0.49,
          "accessibility": "Free",
          "corpus_link": "https://takelab.fer.hr/data/comarg/"
        }
      ]
    },
    {
      "paper_id": "analyzing_argumentative_discourse_units_in_online_interactions",
      "paper_title": "Analyzing argumentative discourse units in online interactions",
      "authors": [
        "Debanjan Ghosh",
        "Smaranda Muresan",
        "Nina Wacholder",
        "Mark Aakhus",
        "Matthew Mitsui"
      ],
      "description": "Propose a multi-step coding approach to annotate ADUs in online interactions, specifically in technical blogs.",
      "year": 2014,
      "paper_link": "https://aclanthology.org/W14-2106/",
      "open_alex_id": "https://openalex.org/W2251521080",
      "annotations": [
        {
          "corpus_id": "technical_blogs",
          "annotation_task": [
            "Argument Component Segmentation",
            "Argument Component Type Classification",
            "Argumentative Relation Identification"
          ],
          "description": "Segmenting text into ADUs and labelling them as either a callout or a target, and further linking callouts to their most recent targets. NOTE: multiple agreement types reported, we only note Krippendorff's Alpha here. IAA was reported seperately for each topic (0.64, 0.73, 0.87, 0.82), below we report a range for these values.",
          "annotator_count": 5,
          "annotator_type": [
            "Expert",
            "Student"
          ],
          "agreement_type": "Krippendorff's Alpha",
          "agreement_score": [0.64, 0.87],
          "deviant_agreement_type": "range",
          "accessibility": "Free",
          "corpus_link": "https://salts.rutgers.edu/identifying-the-language-of-opposition-in-online-interactions/"
        },
        {
          "corpus_id": "technical_blogs",
          "annotation_task": [
            "Argumentative Relation Type Classification"
          ],
          "description": "Fine-grained classification of relations between callouts and targets, as either agree, disagree, or other. NOTE: only a range of Fleiss' Kappa values was reports in the paper.",
          "annotator_count": 5,
          "annotator_type": [
            "Crowd"
          ],
          "agreement_type": "Fleiss' Kappa",
          "agreement_score": [0.45, 0.55],
          "deviant_agreement_type": "range",
          "accessibility": "Free",
          "corpus_link": "https://salts.rutgers.edu/identifying-the-language-of-opposition-in-online-interactions/"
        },
        {
          "corpus_id": "technical_blogs",
          "annotation_task": [
            "Claim Extraction with Stance Classification"
          ],
          "description": "Identifying the stance and rationale of callouts towards their targets, including the exact boundaries of the text segments. NOTE: no agreement reported, although for 50% of callouts the stance and rationale were easily identified by the annotators.",
          "annotator_count": 5,
          "annotator_type": [
            "Crowd"
          ],
          "agreement_type": "Other",
          "agreement_score": "?",
          "deviant_agreement_type": "missing",
          "accessibility": "Free",
          "corpus_link": "https://salts.rutgers.edu/identifying-the-language-of-opposition-in-online-interactions/"
        }
      ]
    },
    {
      "paper_id": "argumentation_mining_in_usergenerated_webdiscourse",
      "paper_title": "Argumentation mining in user-generated web discourse",
      "authors": [
        "Ivan Habernal",
        "Iryna Gurevych"
      ],
      "description": "Exploring various challenges in argumentation mining, in particular by dealing with Web discourse which is notoriously noisy. They introduce a new argumentation model as well as a new corpus annotated according to this model. They further present machine learning approaches to identify argument components.",
      "year": 2017,
      "paper_link": "https://aclanthology.org/J17-1014/",
      "open_alex_id": "https://openalex.org/W3105663928",
      "annotations": [
        {
          "corpus_id": "amugwd_unfiltered",
          "annotation_task": [
            "Other"
          ],
          "description": "Filtering of 990 comments/posts as on-topic persuasive or non-persuasive, yielding a set of 524 persuasive documents.",
          "annotator_count": 3,
          "annotator_type": [
            "Other"
          ],
          "agreement_type": "Fleiss' Kappa",
          "agreement_score": 0.59,
          "accessibility": "Free",
          "corpus_link": "https://tudatalib.ulb.tu-darmstadt.de/items/d4a7ac0c-e7a8-466a-855a-917e42a24342"
        },
        {
          "corpus_id": "amugwd_filtered",
          "annotation_task": [
            "Argument Component Segmentation",
            "Argument Component Type Classification"
          ],
          "description": "Persuasive documents are segmented into argument components and then labelled according to components from an adapted Toulmin model: claim, premise, backing, rebuttal, and refutation. This task includes identifying the exact boundaries/spans of the components, which are assumed to not overlap. Text outside of spans is considered non-argumentative. Individual IAA is reported for each component, here we report the overall Krippendorff's Alpha reported in the paper.",
          "annotator_count": 3,
          "annotator_type": [
            "Other"
          ],
          "agreement_type": "Krippendorff's Alpha",
          "agreement_score": 0.48,
          "accessibility": "Free",
          "corpus_link": "https://tudatalib.ulb.tu-darmstadt.de/items/d4a7ac0c-e7a8-466a-855a-917e42a24342"
        }
      ]
    }
  ]
}
